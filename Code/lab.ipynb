{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d97f8e6",
   "metadata": {},
   "source": [
    "## LAB360: Build an Agentic App with PostgreSQL, GraphRAG, and Microsoft Agent Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e253c9",
   "metadata": {},
   "source": [
    "### Part 3.1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7fafd",
   "metadata": {},
   "source": [
    "**Welcome to the LAB360 Agent App Notebook!**\n",
    "\n",
    "In this notebook, you will build a Microsoft Agent Framework Agent that can reason over our database of legal cases you deployed in the previous steps. You will also incorporate external web service data, and use memory to improve its responses over time.\n",
    "\n",
    "Microsoft Agent Framework is an open-source SDK developed by Microsoft that helps developers create advanced AI agents by combining:\n",
    "\n",
    "- LLMs (Large Language Models) like OpenAI's GPT models\n",
    "- Plugins (custom tools and functions the agent can call)\n",
    "- Memory (saving and recalling past conversations or facts)\n",
    "\n",
    "An Agent in Microsoft Agent Framework is a smart assistant that can:\n",
    "\n",
    "- Respond to user prompts\n",
    "- Decide which plugin functions to call\n",
    "- Use external knowledge sources like databases or APIs\n",
    "- Build better, grounded answers by combining model reasoning with real-world data\n",
    "\n",
    "You are about to connect powerful components:\n",
    "\n",
    "- Azure OpenAI (for embeddings and LLM chat completions)\n",
    "- PostgreSQL with Vector and Graph extensions (for fast semantic and graph search)\n",
    "- APIs for real-world data (historical weather evidence)\n",
    "\n",
    "As you progress, each section of code will incrementally build up these capabilities, and by the final step, you‚Äôll have a highly capable legal research assistant.\n",
    "\n",
    "**Architecture Diagram**\n",
    "\n",
    "![image.png](../Docs/images/arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.2: Setup the Agent App Python imports\n",
    "\n",
    "> **Note:** In your lab environment, we already have the PIP packages pre-deployed that are needed by the import statements in the following code block, so you do not need to install these.  But just for reference and for future usage of this code, here are the packages used:\n",
    "> - PostgreSQL connectivity (`psycopg`, `psycopg-binary`, `psycopg-pool`)\n",
    "> - Modeling and validation (`pydantic`)\n",
    "> - OpenAI and Microsoft Agent Framework integration (`openai`, `agent-framework`)\n",
    "> - Notebook compatibility (`nest_asyncio`, `ipykernel`)\n",
    "\n",
    "Local setup:\n",
    "\n",
    "```python\n",
    "python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "This set of imports prepares the technical foundation for building an AI-powered agent that interacts with a PostgreSQL database and OpenAI services. `nest_asyncio` is used to allow nested event loops, which is important when running asynchronous code inside a Jupyter notebook. Core Python modules like `os`, `asyncio`, `uuid`, and `requests` handle environment access, asynchronous execution, unique ID generation, and external API calls, respectively. `psycopg2` provides database connectivity to PostgreSQL, while `pydantic` offers structured data validation and modeling.\n",
    "\n",
    "The Microsoft Agent Framework libraries enable creation of intelligent agents (`ChatCompletionAgent`), define plugins and function tools (`kernel_function`), manage prompt settings, and handle retrieval-augmented memory. Finally, Azure OpenAI integration components (`AzureChatCompletion`, `AzureTextEmbedding`) allow the agent to generate responses and embeddings using cloud-based AI models.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Run the cell below using the \"‚ñ∂\" icon next to the cell.\n",
    "\n",
    "1. This will run the code and show the output below.  Since these are just imports, there is nothing to show at the end other than a check mark showing success.\n",
    "\n",
    "    > **Note:** The first time this code block is ran, it may take around 20-30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "844b751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os, asyncio, uuid, requests\n",
    "import psycopg\n",
    "from typing import Annotated\n",
    "from pydantic import Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Agent Framework\n",
    "from agent_framework import ChatAgent, ChatMessageStore\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import ai_function, ChatMessage, TextContent, Role\n",
    "\n",
    "# Azure credentials\n",
    "from azure.identity import DefaultAzureCredential, AzureCliCredential\n",
    "\n",
    "# Agent Framework Memory\n",
    "from agent_framework import ChatMessageStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afebe0b",
   "metadata": {},
   "source": [
    "### Part 3.3: Environment Setup\n",
    "\n",
    "Before running the notebook, we need to ensure our environment variables are properly set up. If you've followed the lab instructions and run `azd up` successfully, most of the required environment variables should already be written to a `.env` file in the project root by the `write_env.sh` script.\n",
    "\n",
    "The `.env` file should contain:\n",
    "- Azure OpenAI configuration (endpoint, key, deployment)\n",
    "- Database configuration (host, name, user, password, etc.)\n",
    "\n",
    "If you need to create a `.env` file manually, you can copy the `.env.sample` file in the project root and fill in your specific values.\n",
    "\n",
    "Run the following code block to load the environment variables from the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1d2a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# Choose a credential strategy\n",
    "azure_credential = DefaultAzureCredential()\n",
    "azure_cli_credential = AzureCliCredential()\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT   = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AZURE_OPENAI_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]\n",
    "AZURE_OPENAI_KEY        = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "AZURE_EMBED_DEPLOYMENT  = os.environ[\"AZURE_EMBED_DEPLOYMENT\"]\n",
    "AZURE_API_VERSION       = os.environ[\"AZURE_API_VERSION\"]\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\":     os.environ[\"AZURE_PG_HOST\"],\n",
    "    \"dbname\":   os.environ[\"AZURE_PG_NAME\"],\n",
    "    \"user\":     os.environ[\"AZURE_PG_USER\"],\n",
    "    \"password\": os.environ[\"AZURE_PG_PASSWORD\"],\n",
    "    \"port\":     os.environ[\"AZURE_PG_PORT\"],\n",
    "    \"sslmode\":  os.environ.get(\"AZURE_PG_SSLMODE\", \"require\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194337c",
   "metadata": {},
   "source": [
    "### Part 3.4: Create Microsoft Agent Framework Plugin for Basic Database Queries\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "In this step, we create a custom plugin called DatabaseSearchPlugin to give our agent the ability to interact directly with the case law database using basic SQL queries. This plugin uses the psycopg2 library to establish a connection to PostgreSQL, execute queries, and return results. We define two simple but important functions: `count_cases()` to return the total number of cases in the database, and `search_cases(keyword)` to perform a keyword search against case opinions. Each function is decorated with `@kernel_function`, which registers it as a callable tool within the Microsoft Agent Framework framework. This makes these database operations available to the agent automatically during conversation, enabling the agent to retrieve real-time, grounded information from our dataset.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review the code below, notice the print statements outputting to the terminal the name of the function when it is called.  This will be helpful later when we run the agent, and we want to see what functions it chose to call.\n",
    "\n",
    "1. Run the cell below using the \"‚ñ∂\" icon next to the cell.\n",
    "\n",
    "1. This will run the code and show the output below.  Since these are just imports, there is nothing to show at the end other than a check mark showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "284bbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ai_function(description=\"Return the total number of cases in the database.\")\n",
    "def count_cases() -> str:\n",
    "    print(\"count_cases was called\")\n",
    "    with psycopg.connect(**DB_CONFIG) as conn, conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT COUNT(*) FROM cases;\")\n",
    "        n = (cur.fetchone() or [0])[0]\n",
    "        return str(n)\n",
    "\n",
    "@ai_function(description=\"Find cases using an exact keyword match.\")\n",
    "def search_cases(keyword: Annotated[str, Field(description=\"Keyword to ILIKE-match in case opinions\")],\n",
    ") -> str:\n",
    "    print(\"search_cases was called\")\n",
    "    with psycopg.connect(**DB_CONFIG) as conn, conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT id, name, opinion\n",
    "            FROM cases\n",
    "            WHERE opinion ILIKE %s\n",
    "            LIMIT 10;\n",
    "            \"\"\",\n",
    "            (f\"%{keyword}%\",),\n",
    "        )\n",
    "        rows = cur.fetchall()\n",
    "    if not rows:\n",
    "        return \"No matches\"\n",
    "    return \"\\n\".join(f\"{r[0]}: {r[1]}: {r[2][:1000]}\" for r in rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0006bb",
   "metadata": {},
   "source": [
    "### Part 3.5: Test Run of our New Agent\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "Now that we have created our first plugin, we're ready to assemble and test an initial version of our agent. In this step, we create a default `OpenAIChatPromptExecutionSettings` to define basic settings. We then create an instance of `AzureChatCompletion`, which serves as the underlying communication layer between our agent and Azure OpenAI. Using these components, we instantiate a `ChatCompletionAgent`, providing it a name, a set of behavioral instructions, and a list of available plugins (in this case, just `DatabaseSearchPlugin`).\n",
    "\n",
    "Finally, we send a sample user query to the agent and retrieve its response. This test validates that our agent can successfully invoke plugin functions, query the database, and integrate the results into a natural language reply.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review the code below, notice the following:\n",
    "    - Inside `ChatCompletionAgent` we define `instructions` which act as notion of a \"system prompt\" for the Agent to define its purpose and goals\n",
    "    - For now we are passing in our `DatabaseSearchPlugin` class, we will be creating more PlugIns to enhance the functionality of our agent in the next steps\n",
    "    - Notice the `user_query` variable, and how it is asking how many cases there are, plus about water leaking cases.\n",
    "\n",
    "1. Run the cell below using the \"‚ñ∂\" icon next to the cell.  This invokes the agent and subsequent LLM calls, this may take a few moments to run.\n",
    "\n",
    "1. After the code runs, notice the following:\n",
    "    - There should have been 2 functions called: `count_cases` and `search_cases`\n",
    "    - This happened because the agent interpreted the prompt and made a decision to call these 2 functions\n",
    "    - Notice how we got back a clear response of 377 cases are in our database.  This was based on our `count_cases` database function giving the LLM grounded truth about our dataset.\n",
    "    - Lastly, notice how we asked for 10 cases, but only got 2.  This is because our `search_cases` function is just the ILIKE operator and not yet using a vector search.  It could only find 2 cases that matching using the basic keyword ILIKE search.  In our next lab sections, we will see how we can improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a76e081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Functions the Agent Called: //\n",
      "count_cases was called\n",
      "search_cases was called\n",
      "count_cases was called\n",
      "search_cases was called\n",
      "// Agent Response: //\n",
      "It seems I encountered an issue retrieving the total number of cases and searching for cases regarding the notion of water leaking. Let me try those requests again.I'm unable to retrieve the information about the total number of cases or find cases related to water leaking due to a technical issue. Let me know if you'd like me to attempt a different approach or assist with something else.\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_KEY\"],    \n",
    ")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=(\n",
    "        \"You are a helpful legal assistant. Respond with the case names, why each is relevant, \"\n",
    "        \"and a short one-sentence summary of the opinion.\"\n",
    "    ),\n",
    "    tools=[count_cases, search_cases],\n",
    ")\n",
    "\n",
    "user_query = \"How many cases are there, and find me 10 cases regarding the notion of water leaking.\"\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "result = await agent.run(user_query)\n",
    "\n",
    "print(\"// Agent Response: //\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1206c174",
   "metadata": {},
   "source": [
    "### Part 3.6: Improve Agent Accuracy by Adding Semantic Operators .rank() function\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "In this step, we add a new plugin called `SemanticRerankingPlugin` to increase the precision of our agent‚Äôs search results. Instead of relying only on keyword matching, this plugin uses semantic search and re-ranking to evaluate results based on the meaning and intent of the user query.\n",
    "\n",
    "It works in two phases: first, it performs a vector similarity search using Azure OpenAI embeddings to find approximately relevant cases; then, it reorders these using a separate model (e.g., `semantic_relevance`) that scores and ranks the results for deeper semantic alignment. This two-step approach helps the agent prioritize results that are not just textually similar, but also topically and contextually relevant‚Äîmaking it ideal for legal queries where nuance matters. As with other tools, this function is registered using `@kernel_function`, so the agent can intelligently decide when to use it.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review the code:\n",
    "    - Notice the following enhancements:\n",
    "        - This plugin introduces a function called `search_semantic_reranked_cases`, designed to deliver higher-quality search results by understanding the semantic meaning of the query rather than relying on basic keyword matches.\n",
    "        - The function is decorated with `@kernel_function`, which makes it available to the agent as a callable tool-this is how Microsoft Agent Framework enables function calling automatically based on user intent.\n",
    "\n",
    "    - Check out the SQL logic inside the code, notice how it includes two key phases:\n",
    "        - (Phase 1) A vector similarity search using OpenAI-generated embeddings to find top 40 candidate cases.\n",
    "        - (Phase 2) A semantic re-ranking step that uses an external re-ranker model (semantic_relevance) to evaluate and reorder those 40 based on relevance scores.\n",
    "        - This hybrid approach helps ensure that even when the user‚Äôs phrasing doesn‚Äôt exactly match the database text, relevant results can still be surfaced based on meaning and context.\n",
    "\n",
    "    - Observe how this plugin builds on the earlier keyword search:\n",
    "        - The previous `search_cases()` method used `ILIKE` for fuzzy keyword matching. That works for exact or near-exact phrases but misses nuance.\n",
    "        - This plugin improves accuracy and recall, especially for complex queries or abstract legal concepts where keyword overlap may be weak.\n",
    "        - This function will be automatically called by the agent if the prompt includes phrases like \"high accuracy is important\" or contains complex, open-ended search intent.\n",
    "        - For example, a prompt like: \"*Help me find the most relevant cases about tenant water damage, with high accuracy*\" will likely trigger this plugin over the basic one.\n",
    "\n",
    "1. Finally, run the code block cell by clicking the \"‚ñ∂\" button on the left side of the code block.\n",
    "    - This will run the code but there will be no output yet.\n",
    "    - Since this is just a class definition, there is nothing to show at the end other than a check mark showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef674482",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ai_function(\n",
    "    description=(\n",
    "        \"Use semantic vector search and re-ranking to find cases that best match the query \"\n",
    "        \"intent. Use when high accuracy is needed.\"\n",
    "    )\n",
    ")\n",
    "def search_semantic_reranked_cases(\n",
    "    query: Annotated[str, Field(description=\"Natural language query for legal cases\")],\n",
    ") -> str:\n",
    "    print(\"search_semantic_reranked_cases was called\")\n",
    "    with psycopg.connect(**DB_CONFIG) as conn, conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            WITH vector_candidates AS (\n",
    "                SELECT\n",
    "                    id AS case_id,\n",
    "                    name AS case_name,\n",
    "                    opinion,\n",
    "                    ROW_NUMBER() OVER (\n",
    "                    ORDER BY opinions_vector <=> azure_openai.create_embeddings('text-embedding-3-small', %s)::vector\n",
    "                    ) AS rank_order\n",
    "                FROM cases\n",
    "                ORDER BY opinions_vector <=> azure_openai.create_embeddings('text-embedding-3-small', %s)::vector\n",
    "                LIMIT 40\n",
    "            ),\n",
    "            ranked_results AS (\n",
    "                SELECT\n",
    "                    case_id, case_name, opinion, rank_order,\n",
    "                    azure_ai.rank(%s, ARRAY[opinion], 'gpt-4o') AS ranking_result\n",
    "                FROM vector_candidates\n",
    "            )\n",
    "            SELECT case_id, case_name, opinion, ranking_result\n",
    "            FROM ranked_results\n",
    "            ORDER BY rank_order\n",
    "            LIMIT 10;\n",
    "            \"\"\",\n",
    "            (query, query, query),\n",
    "        )\n",
    "        rows = cur.fetchall()\n",
    "    if not rows:\n",
    "        return \"No matches\"\n",
    "    return \"\\n\".join(f\"{r[0]}: {r[1]}: {r[2][:1000]}\" for r in rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1491f",
   "metadata": {},
   "source": [
    "### Part 3.7: Add a GraphRAG Query PlugIn to the Agent for Additional Accuracy Improvements\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "In this step, we build another advanced plugin, `GraphDatabasePlugin`, that combines vector search with graph analysis to find the most influential cases related to a query topic. The `search_graph_cases` method first uses an embedding-based similarity search to semantically rank cases from the cases table. This ensures that only cases meaningfully related to the query are considered further.\n",
    "\n",
    "After narrowing the results semantically, the query leverages **Apache AGE** - a PostgreSQL extension that enables property graph querying via Cypher syntax. Specifically, it matches citations (relationships between cases) in the `case_graph` graph. By counting the number of incoming edges (citations) for each case, we can rank cases based on their influence or importance within the graph. Cases with more citations are prioritized, resulting in a more nuanced retrieval that considers both semantic relevance and citation authority.\n",
    "\n",
    "This hybrid retrieval technique is an example of **GraphRAG (Graph Retrieval-Augmented Generation)** and represents a more sophisticated form of grounded information retrieval for legal, academic, or research applications.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Before running this code block, we need to run a SQL script on the database.\n",
    "    - In VS Code, in the folder structure, in the folder `./Scripts/` navigate to the `create_graph.sql` file\n",
    "    - Once inside the file, still in VS Code, press on the keyboard `CTRL+SHIFT+P` to open the VS Code action panel, type `PGSQL Connect` and select the top `PGSQL: Connect` option\n",
    "    - Once prompted, select the Connection you made in the earlier steps in the lab\n",
    "    - You will then be asked the port number for the Connection, just hit `enter` to accept the default\n",
    "    - You should now be Connected to your database in the `create_graph.sql` file\n",
    "    - In the editor window, click the \">\" button in the top right to run the script\n",
    "    - This will build our graph database via the Apache AGE extension in our Azure PostgreSQL database using our loaded 377 legal cases\n",
    "\n",
    "1. Next, because we are using the Apache AGE PostgreSQL extension to provide us Graph database capabilities, we need to enable the extension on our database.\n",
    "    - Run the following PowerShell script within VS Code\n",
    "    - Within VS Code, open a new terminal, and at the following path, enter:\n",
    "\n",
    "        `PS C:\\Users\\LabUser\\Downloads\\pg-af-agents-lab> .\\Scripts\\load_age.ps1`\n",
    "\n",
    "        > **Note:** This will run through 3 main commands, all together will take around 60-120 seconds.\n",
    "\n",
    "1. Review the code:\n",
    "    - This plugin allows the agent to find legal cases that are not only semantically similar to a user's query but also highly cited by other cases - providing both relevance and legal importance. The `@kernel_function` decorator makes this method callable by the agent.\n",
    "    - Look at the `semantic_ranked` CTE (Common Table Expression). This ranks cases by their similarity to the input query using embedding-based vector comparison (<=>). The function limits results to the top 60 most semantically similar opinions using Azure OpenAI‚Äôs embedding model.\n",
    "    - Examine the graph CTE. It runs a Cypher query on the `case_graph` to count how many times each case is cited by others. These citation counts are joined to the semantic results using the case ID. This allows the plugin to prioritize not just relevant cases, but those that are also influential in the citation network.\n",
    "    - The final `SELECT` returns 10 cases with the highest number of citations among the semantically relevant ones. The list is ordered by refs `DESC`, meaning more citations come first. Each opinion is truncated to the first 1000 characters to keep responses concise.\n",
    "\n",
    "1. Finally, run the code block cell by clicking the \"‚ñ∂\" button on the left side of the code block.\n",
    "    - This will run the code but there will be no output yet.\n",
    "    - Since this is again just a class definition, there is nothing to show at the end other than a check mark showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d2ec57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ai_function(\n",
    "    description=(\n",
    "        \"Find important cases with high citation counts about the topic. \"\n",
    "        \"Uses semantic narrowing + graph citation counts.\"\n",
    "    )\n",
    ")\n",
    "def search_graph_cases(\n",
    "    query: Annotated[str, Field(description=\"Topic to search for via semantic+graph rank\")],\n",
    ") -> str:\n",
    "    print(\"search_graph_cases was called\")\n",
    "    with psycopg.connect(**DB_CONFIG) as conn, conn.cursor() as cur:\n",
    "        cur.execute('SET search_path = public, ag_catalog, \"$user\";')\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            WITH semantic_ranked AS (\n",
    "                SELECT id, name, opinion, opinions_vector\n",
    "                FROM cases\n",
    "                ORDER BY opinions_vector <=> azure_openai.create_embeddings('text-embedding-3-small', %s)::vector\n",
    "                LIMIT 60\n",
    "            ),\n",
    "            graph AS (\n",
    "                SELECT graph_query.refs, semantic_ranked.*, graph_query.case_id\n",
    "                FROM semantic_ranked\n",
    "                LEFT JOIN cypher('case_graph', $$\n",
    "                    MATCH ()-[r]->(n)\n",
    "                    RETURN n.case_id, COUNT(r) AS refs\n",
    "                $$) AS graph_query(case_id TEXT, refs BIGINT)\n",
    "                ON semantic_ranked.id = graph_query.case_id::int\n",
    "            )\n",
    "            SELECT id, name, opinion\n",
    "            FROM graph\n",
    "            ORDER BY refs DESC NULLS LAST\n",
    "            LIMIT 10;\n",
    "            \"\"\",\n",
    "            (query,),\n",
    "        )\n",
    "        rows = cur.fetchall()\n",
    "    if not rows:\n",
    "        return \"No matches\"\n",
    "    return \"\\n\".join(f\"{r[0]}: {r[1]}: {r[2][:1000]}\" for r in rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3164fd",
   "metadata": {},
   "source": [
    "### Part 3.8: Re-Assemble our Agent with new advanced PlugIns and Re-Test\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "In this step, we re-assemble the full agent by attaching all of the custom plugins we‚Äôve created so far: `DatabaseSearchPlugin`, `SemanticRerankingPlugin`, and `GraphDatabasePlugin`. These plugins give the agent access to different querying strategies, from simple keyword searches to advanced semantic filtering and graph-based citation analysis. By registering all plugins in the plugins list, we enable the agent to choose the right tool based on the intent expressed in the user‚Äôs prompt.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review the code below, notice the following:\n",
    "    - We only need to re-define our agent object using the `ChatCompletionAgent` class\n",
    "    - Notice we are now adding our new PlugIns on the line:\n",
    "        - `plugins=[DatabaseSearchPlugin(DB_CONFIG),SemanticRerankingPlugin(DB_CONFIG),GraphDatabasePlugin(DB_CONFIG)],`    \n",
    "    - Notice the `user_query` variables, there are some additional ones you can try testing yourself by uncommenting one at a time, then re-running the code cell\n",
    "\n",
    "1. Run the cell below using the \">\" icon next to the cell.  This invokes the agent and subsequent LLM calls, this may take a few moments to run.\n",
    "\n",
    "1. After the code runs, notice the following:\n",
    "    - Depending on the prompt you chosen, there should have been between 2-3 functions called, such as: `search_graph_cases` and `search_semantic_reranked_cases`\n",
    "    - Notice how we asked for 10 cases, and now got 10 cases. This is because the we are now using semantic vector search, not just keyword search for the database queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51df009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Functions the Agent Called: //\n",
      "count_cases was called\n",
      "search_graph_cases was called\n",
      "count_cases was called\n",
      "search_graph_cases was called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 21:08:24 - c:\\Users\\jaredmeade\\source\\repos\\pg-af-agents-lab\\.venv\\Lib\\site-packages\\agent_framework\\_tools.py:1613 - WARNING] Maximum consecutive function call errors reached (3). Stopping further function calls for this request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Agent Response: //\n",
      "It seems that I encountered an error while trying to retrieve the total number of cases and searching for highly cited cases on water leakage in apartments. Let me attempt each query individually to resolve this.I was unable to determine the total number of cases in the database. I'll now try again to find relevant cases related to water leakage from an upstairs apartment.\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_KEY\"],    \n",
    ")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=(\n",
    "        \"You are a helpful legal assistant. Respond with case names, why each is relevant, \"\n",
    "        \"and a short one-sentence summary of each opinion.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        count_cases,\n",
    "        search_cases,\n",
    "        search_semantic_reranked_cases,\n",
    "        search_graph_cases,\n",
    "    ],\n",
    ")\n",
    "\n",
    "user_query = (\n",
    "    \"How many cases are there overall?\"\n",
    "    \"Also, help me find 10 highly relevant cases related to water leaking in my client's \"\n",
    "    \"apartment from the floor above. High accuracy and high number of citations are important. \"    \n",
    ")\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "result = await agent.run(user_query)\n",
    "print(\"// Agent Response: //\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32517a",
   "metadata": {},
   "source": [
    "### Part 3.9: Adding a Weather PlugIn to the Agent\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "To enhance our legal assistant with real-world context, we introduce a `WeatherPlugin` that enables the agent to retrieve historical weather data (specifically rainfall) based on a given date and geographic location. This is especially useful in real estate or tenant-landlord disputes where weather-related damage (e.g., leaks or flooding) may be a legal factor. The plugin uses the Open-Meteo Archive API, a free and reliable weather data service.\n",
    "\n",
    "When a user prompt mentions a need for weather data‚Äîsuch as \"What was the rainfall on Feb 1, 2024, in Seattle?\"‚Äîthe agent will automatically call this function. The returned data provides accurate, grounded evidence that enhances the agent‚Äôs response and credibility.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review the code below and observe the following:\n",
    "    - The `@kernel_function` decorator registers this function so the agent can call it based on user intent.\n",
    "    - The plugin uses `requests.get()` to make a live API call to Open-Meteo, passing latitude, longitude, and date parameters.\n",
    "    - The response is parsed from JSON and extracts the precipitation value from the `daily.precipitation_sum` array.\n",
    "    - The result is returned as a readable string with the date, coordinates, and rainfall in millimeters.\n",
    "\n",
    "1. Run the cell below using the \"‚ñ∂\" (Run) button. There is no visible output until the function is called by the agent in a relevant prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf9190f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ai_function(description=\"Get total precipitation (mm) on a given date (YYYY-MM-DD) and (lat, lon).\")\n",
    "def get_historical_rainfall(\n",
    "    date: Annotated[str,  Field(description=\"Date in YYYY-MM-DD\")],\n",
    "    latitude: Annotated[float, Field(description=\"Latitude (WGS84)\")],\n",
    "    longitude: Annotated[float, Field(description=\"Longitude (WGS84)\")],\n",
    ") -> str:\n",
    "    print(\"get_historical_rainfall was called\")\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": date,\n",
    "        \"end_date\":   date,\n",
    "        \"daily\":      \"precipitation_sum\",\n",
    "        \"timezone\":   \"UTC\",\n",
    "    }\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    rain_mm = data[\"daily\"][\"precipitation_sum\"][0]\n",
    "    return f\"On {date} at ({latitude}, {longitude}), total precipitation was {rain_mm} mm.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613a5df",
   "metadata": {},
   "source": [
    "### Part 3.10: Add our new Weather PlugIn to our Agent and Re-Test\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "In this step, we complete our agent by including the new `WeatherPlugin` alongside our database and semantic plugins. This enables the agent to answer more complex, multi-part prompts that require both legal case analysis and external factual grounding‚Äîsuch as historical rainfall on a specific date and location.\n",
    "\n",
    "When a user prompt mentions weather-related conditions (e.g., \"*What was the rainfall on February 1, 2024, in Seattle?*\"), the agent can automatically call the appropriate plugin function. Microsoft Agent Framework handles function selection based on the natural language intent, so all tools are available simultaneously without manual switching. This demonstrates the power of multi-plugin orchestration in agent design‚Äîallowing a single agent to reason across legal data and real-world APIs in one coherent response.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review how the `WeatherPlugin()` is added to the list of available plugins in the `ChatCompletionAgent`.\n",
    "\n",
    "1. Examine the user_query. Note how it includes both:\n",
    "    - A factual request (weather evidence),\n",
    "    - And a legal research task (finding relevant legal cases).\n",
    "\n",
    "1. Run the cell below using the \"‚ñ∂\" (Run) button and observe:\n",
    "    - Which functions the agent chooses to call (check your logs or printed output),\n",
    "    - How the agent combines different results into a single response.\n",
    "    - Try editing the user_query to include other dates or cities and observe how the weather data changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b672c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Functions the Agent Called: //\n",
      "get_historical_rainfall was called\n",
      "search_graph_cases was called\n",
      "search_semantic_reranked_cases was called\n",
      "search_cases was called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 21:08:39 - c:\\Users\\jaredmeade\\source\\repos\\pg-af-agents-lab\\.venv\\Lib\\site-packages\\agent_framework\\_tools.py:1613 - WARNING] Maximum consecutive function call errors reached (3). Stopping further function calls for this request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Agent Response: //\n",
      "The total precipitation recorded in Seattle, WA, on February 1, 2024, was 5.1 mm. However, I encountered an error while retrieving high-citation cases related to water leaking in apartments‚ÄîI'll attempt a different method to obtain those cases.I couldn't retrieve the case information due to a technical issue. Here are a few cases often cited in landlord-tenant disputes for water damage; you may need legal databases for specific citations:\n",
      "\n",
      "1. **Green v. Superior Court (1974)**: Recognized implied warranty of habitability, holding landlords responsible for providing livable conditions.\n",
      "2. **Kline v. 1500 Massachusetts Avenue Apartment Corp. (1970)**: Focused on landlord's responsibility for premises safety.\n",
      "3. **Javins v. First National Realty Corp. (1970)**: Established that landlords must adhere to housing codes, including preventing water damage.\n",
      "4. **Black v. Fox Hills North (1986)**: Examined tenant rights over maintenance failures causing property damage.\n",
      "5. **Neff v. J.C. Penney Co. (1952)**: Dealt with foreseeability of harm due to leaks in rented spaces.\n",
      "\n",
      "I recommend consulting legal research databases like Westlaw or LexisNexis for further specific rulings in your jurisdiction.\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_KEY\"],    \n",
    ")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=(\n",
    "        \"You are a helpful legal assistant. Respond with case names, reasoning for relevance, \"\n",
    "        \"and a one-sentence opinion summary. Use external tools when appropriate.\"\n",
    "    ),\n",
    "    tools=[\n",
    "        count_cases,\n",
    "        search_cases,\n",
    "        search_semantic_reranked_cases,\n",
    "        search_graph_cases,\n",
    "        get_historical_rainfall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "user_query = (\n",
    "    \"What was the rainfall on 2024-02-01 in Seattle, WA? I need this for evidence. \"\n",
    "    \"Also high number of citations is important‚Äîhelp me find 10 highly relevant cases \"\n",
    "    \"related to water leaking in my client's apartment.\"\n",
    ")\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "result = await agent.run(user_query)\n",
    "print(\"// Agent Response: //\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784b47b",
   "metadata": {},
   "source": [
    "### Part 3.11: Adding Memory into the Agent\n",
    "\n",
    "##### üß† *Technical Notes*\n",
    "\n",
    "In this final step, we complete our agent's capabilities by enabling memory using the Microsoft Agent Framework's **InMemoryMessageStore**. This allows the agent to store and recall conversation history‚Äîcreating a more personalized and context-aware experience over time.\n",
    "\n",
    "The Agent Framework's memory system stores the full conversation history as a sequence of messages (user and assistant). When a new prompt is received, we can retrieve past messages and use them to provide context. This memory is especially useful in real-world legal scenarios where a user may build a case over several prompts, and the agent must retain prior details to offer more precise, relevant guidance.\n",
    "\n",
    "##### ‚öôÔ∏è *Code Review Tasks*\n",
    "\n",
    "1. Review how **InMemoryMessageStore** is used to set up conversation memory for the agent.\n",
    "\n",
    "1. Examine how user queries and agent responses are stored as **ChatMessage** objects with roles (USER/ASSISTANT).\n",
    "\n",
    "1. Observe how the conversation history is retrieved and prepended to new prompts for context.\n",
    "\n",
    "1. Run the cell below using the \"‚ñ∂\" (Run) button and inspect:\n",
    "    - How the agent's output incorporates the memory context,\n",
    "    - What gets saved to memory as both the query and the agent's reply,\n",
    "    - How this memory layer enables continuity in multi-turn conversations.\n",
    "\n",
    "1. Test running through the first 3 sample prompts below, by uncommenting a single prompt, one at a time\n",
    "    - As you run through these, this helps to showcase the memory functionality as the Agent keeps track of these facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40f914df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Conversation History //\n",
      "User: ...\n",
      "\n",
      "// Prompt with Memory Context //\n",
      " Here are relevant past facts:\n",
      "- \n",
      "\n",
      "My client has lived in their apartment for 10 years\n",
      "search_semantic_reranked_cases was called\n",
      "search_graph_cases was called\n",
      "search_cases was called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 21:10:00 - c:\\Users\\jaredmeade\\source\\repos\\pg-af-agents-lab\\.venv\\Lib\\site-packages\\agent_framework\\_tools.py:1613 - WARNING] Maximum consecutive function call errors reached (3). Stopping further function calls for this request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "// Agent Response //\n",
      " To assist with your client's landlord-tenant matter or rights concerning tenancy, let's consider legal cases involving long-term tenants and protections provided for them. I'll search for relevant cases involving tenants with extended leasing periods.\n",
      "\n",
      "I will conduct the search now.Without access to case search tools, I can provide examples of commonly cited cases relevant to long-term tenant rights. Here are two:\n",
      "\n",
      "1. **Green v. Superior Court (1974)** - Established implied warranty of habitability, ensuring tenants have livable conditions even after extended leases.  \n",
      "2. **Edwards v. Habib (1968)** - Protects tenants from retaliatory eviction after asserting legal rights, relevant for tenants facing disputes after a long tenancy.  \n",
      "\n",
      "Both cases demonstrate how housing law evolves to protect tenants. If further elaboration or jurisdiction-specific cases are needed, let me know!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Agent Framework Memory with in-memory message store\n",
    "# This stores conversation history for the agent to maintain context across interactions\n",
    "\n",
    "# Create a message store for the agent\n",
    "memory_store = InMemoryMessageStore()\n",
    "\n",
    "# Example user queries to test memory functionality\n",
    "# user_query = \"I am a real estate lawyer\"\n",
    "user_query = \"My client has lived in their apartment for 10 years\"\n",
    "# user_query = \"How many cases are there, and help me find 10 highly relevant water-leak cases with high accuracy.\"\n",
    "\n",
    "# Additional test cases to see how the agent responds:\n",
    "#user_query = \"Find me some cases regarding the notion of my house falling down.\"\n",
    "#user_query = \"Find me 10 cases regarding the notion of water leaking.\"\n",
    "#user_query = \"Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.  Also how many cases are there overall?\"\n",
    "#user_query = \"Bring into 1 list of 10 cases, ranked by relevancy -- Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.\"\n",
    "\n",
    "# 1) Add the user message to memory\n",
    "await memory_store.add_message(\n",
    "    ChatMessage(\n",
    "        role=Role.USER,\n",
    "        content=[TextContent(text=user_query)]\n",
    "    ),\n",
    "    session_id=\"lab_user_1\"\n",
    ")\n",
    "\n",
    "# 2) Retrieve conversation history from memory\n",
    "history = await memory_store.get_messages(session_id=\"lab_user_1\")\n",
    "\n",
    "print(\"// Conversation History //\")\n",
    "for msg in history:\n",
    "    role_name = \"User\" if msg.role == Role.USER else \"Assistant\"\n",
    "    content_text = msg.text if hasattr(msg, 'text') else str(msg)\n",
    "    print(f\"{role_name}: {content_text[:100]}...\")\n",
    "\n",
    "# 3) Build prompt with memory context\n",
    "memory_context = \"\\n\".join([\n",
    "    f\"- {msg.text}\" \n",
    "    for msg in history \n",
    "    if msg.role == Role.USER and hasattr(msg, 'text')\n",
    "])\n",
    "prompt = f\"Here are relevant past facts:\\n{memory_context}\\n\\n{user_query}\"\n",
    "\n",
    "print(\"\\n// Prompt with Memory Context //\\n\", prompt)\n",
    "\n",
    "# 4) Run the agent with memory-augmented prompt\n",
    "result = await agent.run(prompt)\n",
    "print(\"\\n// Agent Response //\\n\", result.text)\n",
    "\n",
    "# 5) Store the agent reply for future continuity\n",
    "await memory_store.add_message(\n",
    "    ChatMessage(\n",
    "        role=Role.ASSISTANT,\n",
    "        content=[TextContent(text=result.text)]\n",
    "    ),\n",
    "    session_id=\"lab_user_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d1a23",
   "metadata": {},
   "source": [
    "## Congratulations you have completed the Lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9dba0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "We have curated additional resources to enhance your ongoing journey in building AI agents and AI-powered applications with Azure Database for PostgreSQL.\n",
    "\n",
    "- A more detailed blog post about the legal case example of lab in the [GraphRAG Solution for Azure Database for PostgreSQL](https://aka.ms/pg-graphrag) check the code in the [GitHub repository](https://aka.ms/postgres-graphrag-solution).\n",
    "- Learn more about [Graph data in Azure Database for PostgreSQL](https://aka.ms/age-blog).\n",
    "- Get familiar with the new [PostgreSQL extension for Visual Studio Code]().\n",
    "- Learn more about Semantic Ranking with the [Semantic Ranker Solution Accelerator](https://aka.ms/semantic-ranker-solution-accelerator-pg-blog) and its associated [GitHub repository](https://aka.ms/pg-ranker-repo).\n",
    "- Finally, our more recent solutions accelerator [Build your own advanced AI Copilot with Postgres](http://aka.ms/pg-byoac-docs) teaches you how to extract data from statements of work (SOWs) and invoices in PDF files and use AI to validate them, more details in the [GitHub repo](http://aka.ms/pg-byoac-repo)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
